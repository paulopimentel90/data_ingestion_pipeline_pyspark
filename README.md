# data_ingestion_pipeline_pyspark
A simple and modular data ingestion pipeline built with PySpark. This project extracts data from CSV files, applies basic transformations, and saves clean data as optimized Parquet files. Designed for scalability and easy integration, ideal for batch ETL workflows and data lake ingestion.
